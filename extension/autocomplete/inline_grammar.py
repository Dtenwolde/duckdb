import os
import argparse

parser = argparse.ArgumentParser(description='Inline the auto-complete PEG grammar files')
parser.add_argument(
    '--print', action='store_true', help='Print the grammar instead of writing to a file', default=False
)
parser.add_argument(
    '--grammar-file',
    action='store_true',
    help='Write the grammar to a .gram file instead of a C++ header',
    default=False,
)

args = parser.parse_args()

autocomplete_dir = 'extension/autocomplete'
statements_dir = os.path.join(autocomplete_dir, 'grammar', 'statements')
keywords_dir = os.path.join(autocomplete_dir, 'grammar', 'keywords')
target_file = os.path.join(autocomplete_dir, 'include', 'inlined_grammar.hpp')

contents = ""

CATEGORY_MAP = {
    "reserved_keywords.list": "RESERVED_KEYWORD",
    "unreserved_keywords.list": "UNRESERVED_KEYWORD",
    "colname_keywords.list": "COL_NAME_KEYWORD",
    "func_name_keywords.list": "TYPE_FUNC_NAME_KEYWORD",
    "type_name_keywords.list": "TYPE_FUNC_NAME_KEYWORD",  # merged in C++
}

# For validation
reserved_set = set()
unreserved_set = set()
col_func_type_set = set()

# Final output list
kwlist = []

def load_keywords(filepath):
    with open(filepath, "r") as f:
        return [line.strip() for line in f if line.strip()]

# Validate and load all keywords
for filename in os.listdir(keywords_dir):
    if filename not in CATEGORY_MAP:
        continue

    category = CATEGORY_MAP[filename]
    keywords = load_keywords(os.path.join(keywords_dir, filename))

    for kw in keywords:
        if category == "RESERVED_KEYWORD":
            if kw in reserved_set:
                print(f"Duplicate keyword '{kw}' in reserved keywords")
                exit(1)
            if kw in unreserved_set or kw in col_func_type_set:
                print(f"Keyword '{kw}' is marked as both reserved and something else")
                exit(1)
            reserved_set.add(kw)
        elif category == "UNRESERVED_KEYWORD":
            if kw in unreserved_set:
                print(f"Duplicate keyword '{kw}' in unreserved keywords")
                exit(1)
            if kw in reserved_set:
                print(f"Keyword '{kw}' is marked as both reserved and unreserved")
                exit(1)
            unreserved_set.add(kw)
        elif category in ["COL_NAME_KEYWORD", "TYPE_FUNC_NAME_KEYWORD"]:
            if kw in reserved_set:
                print(f"Keyword '{kw}' is marked as both reserved and {category}")
                exit(1)
            if kw in unreserved_set:
                print(f"Keyword '{kw}' is marked as both unreserved and {category}")
                exit(1)
            # allow duplicates between COL/TYPE/FUNC
            col_func_type_set.add(kw)

        kwlist.append((kw, category))

# Sort for determinism
kwlist.sort(key=lambda x: x[0].lower())

# Generate C++ map file
with open(os.path.join(autocomplete_dir, "keyword_map.cpp"), "w") as f:
    f.write("/* THIS FILE WAS AUTOMATICALLY GENERATED BY inline_grammar.py */\n")
    f.write("#include \"keyword_helper.hpp\"\n\n")
    f.write("namespace duckdb {\n")
    f.write("void KeywordHelper::InitializeKeywordMap() {\n")
    f.write("    if (initialized) return;\n")
    f.write("    initialized = true;\n")

    for kw, category in kwlist:
        cpp_cat = {
            "RESERVED_KEYWORD": "KeywordCategory::KEYWORD_RESERVED",
            "UNRESERVED_KEYWORD": "KeywordCategory::KEYWORD_UNRESERVED",
            "COL_NAME_KEYWORD": "KeywordCategory::KEYWORD_COL_NAME",
            "TYPE_FUNC_NAME_KEYWORD": "KeywordCategory::KEYWORD_TYPE_FUNC"
        }.get(category, "KeywordCategory::KEYWORD_NONE")

        f.write(f'    keyword_map["{kw.lower()}"] = {cpp_cat};\n')

    f.write("}\n")
    f.write("}\n")

for file in os.listdir(statements_dir):
    if not file.endswith('.gram'):
        raise Exception(f"File {file} does not end with .gram")
    with open(os.path.join(statements_dir, file), 'r') as f:
        contents += f.read() + "\n"

if args.print:
    print(contents)
    exit(0)

if args.grammar_file:
    grammar_file = target_file.replace('.hpp', '.gram')
    with open(grammar_file, 'w+') as f:
        f.write(contents)
    exit(0)


def get_grammar_bytes(contents, add_null_terminator=True):
    result_text = ""
    for line in contents.split('\n'):
        if len(line) == 0:
            continue
        result_text += "\t\"" + line.replace('\\', '\\\\').replace('"', '\\"') + "\\n\"\n"
    return result_text


with open(target_file, 'w+') as f:
    f.write(
        '''/* THIS FILE WAS AUTOMATICALLY GENERATED BY inline_grammar.py */

namespace duckdb {

const char INLINED_PEG_GRAMMAR[] = {
'''
        + get_grammar_bytes(contents)
        + '''
};

} // namespace duckdb
'''
    )
